{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-10T12:50:51.891638Z",
     "start_time": "2025-12-10T12:50:45.011250Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import Qwen3VLForConditionalGeneration, AutoProcessor\n",
    "\n",
    "# Qwen3-VL 属于视觉语言多模态模型，其配置类 Qwen3VLConfig 并不在 AutoModelForCausalLM 支持的纯文本模型列表中\n",
    "\n",
    "# 模型路径（替换为你下载的本地路径）\n",
    "MODEL_PATH = r\"E:/models/Qwen3-VL-2B-Instruct\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T12:50:56.950375Z",
     "start_time": "2025-12-10T12:50:53.946557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 加载处理器（Qwen3-VL 用 AutoProcessor，集成了图像和文本处理）\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=False  # Qwen 系列推荐关闭 fast tokenizer\n",
    ")\n",
    "\n",
    "# 加载模型\n",
    "model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    dtype=\"auto\", \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model.eval()  # 推理模式"
   ],
   "id": "bb565ff5985c6e0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen3VLForConditionalGeneration(\n",
       "  (model): Qwen3VLModel(\n",
       "    (visual): Qwen3VLVisionModel(\n",
       "      (patch_embed): Qwen3VLVisionPatchEmbed(\n",
       "        (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
       "      )\n",
       "      (pos_embed): Embedding(2304, 1024)\n",
       "      (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
       "      (blocks): ModuleList(\n",
       "        (0-23): 24 x Qwen3VLVisionBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Qwen3VLVisionAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (mlp): Qwen3VLVisionMLP(\n",
       "            (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (act_fn): GELUTanh()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (merger): Qwen3VLVisionPatchMerger(\n",
       "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (act_fn): GELU(approximate='none')\n",
       "        (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "      )\n",
       "      (deepstack_merger_list): ModuleList(\n",
       "        (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
       "          (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
       "          (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (act_fn): GELU(approximate='none')\n",
       "          (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (language_model): Qwen3VLTextModel(\n",
       "      (embed_tokens): Embedding(151936, 2048)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen3VLTextDecoderLayer(\n",
       "          (self_attn): Qwen3VLTextAttention(\n",
       "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "            (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "            (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
       "          )\n",
       "          (mlp): Qwen3VLTextMLP(\n",
       "            (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "            (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
       "            (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
       "            (act_fn): SiLUActivation()\n",
       "          )\n",
       "          (input_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
       "      (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T12:57:28.089996Z",
     "start_time": "2025-12-10T12:57:28.083992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"模型结构概述：\")\n",
    "print(model)"
   ],
   "id": "b44619d4c837e6ff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型结构概述：\n",
      "Qwen3VLForConditionalGeneration(\n",
      "  (model): Qwen3VLModel(\n",
      "    (visual): Qwen3VLVisionModel(\n",
      "      (patch_embed): Qwen3VLVisionPatchEmbed(\n",
      "        (proj): Conv3d(3, 1024, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n",
      "      )\n",
      "      (pos_embed): Embedding(2304, 1024)\n",
      "      (rotary_pos_emb): Qwen3VLVisionRotaryEmbedding()\n",
      "      (blocks): ModuleList(\n",
      "        (0-23): 24 x Qwen3VLVisionBlock(\n",
      "          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Qwen3VLVisionAttention(\n",
      "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
      "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (mlp): Qwen3VLVisionMLP(\n",
      "            (linear_fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (linear_fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (act_fn): GELUTanh()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (merger): Qwen3VLVisionPatchMerger(\n",
      "        (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
      "        (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "        (act_fn): GELU(approximate='none')\n",
      "        (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "      )\n",
      "      (deepstack_merger_list): ModuleList(\n",
      "        (0-2): 3 x Qwen3VLVisionPatchMerger(\n",
      "          (norm): LayerNorm((4096,), eps=1e-06, elementwise_affine=True)\n",
      "          (linear_fc1): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "          (act_fn): GELU(approximate='none')\n",
      "          (linear_fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (language_model): Qwen3VLTextModel(\n",
      "      (embed_tokens): Embedding(151936, 2048)\n",
      "      (layers): ModuleList(\n",
      "        (0-27): 28 x Qwen3VLTextDecoderLayer(\n",
      "          (self_attn): Qwen3VLTextAttention(\n",
      "            (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (k_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
      "            (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
      "            (q_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
      "            (k_norm): Qwen3VLTextRMSNorm((128,), eps=1e-06)\n",
      "          )\n",
      "          (mlp): Qwen3VLTextMLP(\n",
      "            (gate_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "            (up_proj): Linear(in_features=2048, out_features=6144, bias=False)\n",
      "            (down_proj): Linear(in_features=6144, out_features=2048, bias=False)\n",
      "            (act_fn): SiLUActivation()\n",
      "          )\n",
      "          (input_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
      "          (post_attention_layernorm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
      "        )\n",
      "      )\n",
      "      (norm): Qwen3VLTextRMSNorm((2048,), eps=1e-06)\n",
      "      (rotary_emb): Qwen3VLTextRotaryEmbedding()\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=2048, out_features=151936, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T12:58:24.942174Z",
     "start_time": "2025-12-10T12:58:24.936978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印模型参数总量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"模型总参数量: {total_params / 1e9:.2f}B\")"
   ],
   "id": "ae19aedbd34ae55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量: 2.13B\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T12:58:45.280523Z",
     "start_time": "2025-12-10T12:58:45.276022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 打印配置（查看超参数，如隐藏层大小、层数等）\n",
    "print(\"模型配置：\")\n",
    "print(model.config)"
   ],
   "id": "8936d99d4f28804b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型配置：\n",
      "Qwen3VLConfig {\n",
      "  \"architectures\": [\n",
      "    \"Qwen3VLForConditionalGeneration\"\n",
      "  ],\n",
      "  \"image_token_id\": 151655,\n",
      "  \"model_type\": \"qwen3_vl\",\n",
      "  \"text_config\": {\n",
      "    \"attention_bias\": false,\n",
      "    \"attention_dropout\": 0.0,\n",
      "    \"bos_token_id\": 151643,\n",
      "    \"dtype\": \"bfloat16\",\n",
      "    \"eos_token_id\": 151645,\n",
      "    \"head_dim\": 128,\n",
      "    \"hidden_act\": \"silu\",\n",
      "    \"hidden_size\": 2048,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 6144,\n",
      "    \"max_position_embeddings\": 262144,\n",
      "    \"model_type\": \"qwen3_vl_text\",\n",
      "    \"num_attention_heads\": 16,\n",
      "    \"num_hidden_layers\": 28,\n",
      "    \"num_key_value_heads\": 8,\n",
      "    \"rms_norm_eps\": 1e-06,\n",
      "    \"rope_scaling\": {\n",
      "      \"mrope_interleaved\": true,\n",
      "      \"mrope_section\": [\n",
      "        24,\n",
      "        20,\n",
      "        20\n",
      "      ],\n",
      "      \"rope_type\": \"default\"\n",
      "    },\n",
      "    \"rope_theta\": 5000000,\n",
      "    \"tie_word_embeddings\": true,\n",
      "    \"use_cache\": true,\n",
      "    \"vocab_size\": 151936\n",
      "  },\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"transformers_version\": \"4.57.3\",\n",
      "  \"video_token_id\": 151656,\n",
      "  \"vision_config\": {\n",
      "    \"deepstack_visual_indexes\": [\n",
      "      5,\n",
      "      11,\n",
      "      17\n",
      "    ],\n",
      "    \"depth\": 24,\n",
      "    \"hidden_act\": \"gelu_pytorch_tanh\",\n",
      "    \"hidden_size\": 1024,\n",
      "    \"in_channels\": 3,\n",
      "    \"initializer_range\": 0.02,\n",
      "    \"intermediate_size\": 4096,\n",
      "    \"model_type\": \"qwen3_vl\",\n",
      "    \"num_heads\": 16,\n",
      "    \"num_position_embeddings\": 2304,\n",
      "    \"out_hidden_size\": 2048,\n",
      "    \"patch_size\": 16,\n",
      "    \"spatial_merge_size\": 2,\n",
      "    \"temporal_patch_size\": 2\n",
      "  },\n",
      "  \"vision_end_token_id\": 151653,\n",
      "  \"vision_start_token_id\": 151652\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:06:38.886441Z",
     "start_time": "2025-12-10T13:06:38.882584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. 基础用法：纯文本交互（无图像，仅文本对话）\n",
    "def pure_text_interaction(prompt: str, max_new_tokens: int = 512) -> str:\n",
    "    \"\"\"\n",
    "    纯文本交互：输入提示，生成响应。\n",
    "    示例：prompt = \"你好，介绍一下自己。\"\n",
    "    \"\"\"\n",
    "    # 构建消息（Qwen 格式：list of dicts）\n",
    "    messages = [{\"role\": \"user\", \n",
    "                 \"content\": [{\"type\": \"text\", \n",
    "                              \"text\": prompt}]}]\n",
    "    \n",
    "    # 应用聊天模板\n",
    "    text = processor.apply_chat_template(messages, \n",
    "                                         tokenize=False, \n",
    "                                         add_generation_prompt=True)\n",
    "    \n",
    "    # 处理输入（无图像）\n",
    "    inputs = processor(text=text, \n",
    "                       return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 生成\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # 解码（跳过特殊 token）\n",
    "    response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 提取 assistant 部分（去除历史）\n",
    "    response = response.split(\"assistant\\n\")[-1].strip() if \"assistant\\n\" in response else response\n",
    "    return response"
   ],
   "id": "cff809c0572418c5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:06:45.230326Z",
     "start_time": "2025-12-10T13:06:41.106151Z"
    }
   },
   "cell_type": "code",
   "source": "print(pure_text_interaction(\"你好，Qwen3-VL 是什么？\"))",
   "id": "8479cb01d139def2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！Qwen3-VL 是通义实验室推出的一款基于大语言模型的视觉理解模型。它结合了强大的自然语言处理能力与先进的计算机视觉技术，能够理解并生成与图像相关的文本信息，同时也能进行图像生成和描述。Qwen3-VL 旨在为用户提供更加丰富和直观的交互体验，特别是在图像理解和生成方面具有显著优势。\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:10:35.885835Z",
     "start_time": "2025-12-10T13:10:35.881786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. 核心用法：图文问答（单张图片 + 文本输入）\n",
    "from PIL import Image\n",
    "def image_text_qa(image_path: str, prompt: str, max_new_tokens: int = 512) -> str:\n",
    "    \"\"\"\n",
    "    图文问答：输入图片路径和提示，支持描述、视觉 QA、OCR 等。\n",
    "    示例：\n",
    "    - 图片描述：prompt = \"请详细描述这张图片。\"\n",
    "    - 视觉 QA：prompt = \"图片中有什么动物？\"\n",
    "    - OCR：prompt = \"提取图片中的所有文字。\"\n",
    "    \"\"\"\n",
    "    # 打开图片\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    # 构建消息\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\", \"image\": image},\n",
    "            {\"type\": \"text\", \"text\": prompt}\n",
    "        ]\n",
    "    }]\n",
    "    \n",
    "    # 应用聊天模板\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 处理输入（包括图像）\n",
    "    inputs = processor(text=text, images=image, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 生成\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # 解码\n",
    "    response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 提取 assistant 部分\n",
    "    response = response.split(\"assistant\\n\")[-1].strip() if \"assistant\\n\" in response else response\n",
    "    return response"
   ],
   "id": "db09bacc97c3d773",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:11:04.880033Z",
     "start_time": "2025-12-10T13:10:38.108541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"图片描述：\")\n",
    "print(image_text_qa(\"../test_data/1.png\", \"请分析这张图片。\"))"
   ],
   "id": "48064f7bebdb63f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片描述：\n",
      "好的，这张图片是一张胸部正位X光片，展示了胸廓、肺部、心脏和骨骼的解剖结构。\n",
      "\n",
      "---\n",
      "\n",
      "### 图像分析\n",
      "\n",
      "- **影像类型**：胸部正位X光片（Chest X-ray）\n",
      "- **观察角度**：前后位（AP view）\n",
      "- **主要结构**：\n",
      "  - **骨骼**：清晰可见的锁骨、肩胛骨、肋骨和胸骨。肋骨在肺野中呈清晰的弧形。\n",
      "  - **胸腔**：包括胸椎、肋骨、胸骨和胸腔内脏器。\n",
      "  - **肺部**：肺野呈现为双侧的透亮区域，肺纹理清晰，提示肺组织正常。\n",
      "  - **心脏**：心脏轮廓清晰，位于胸腔中央偏左，大小正常。\n",
      "  - **膈肌**：膈肌呈穹隆状，位置正常。\n",
      "  - **纵隔**：纵隔结构清晰，未见明显异常。\n",
      "\n",
      "- **关键观察点**：\n",
      "  - **肺部**：双肺透亮度正常，肺野清晰，未见明显积液或气胸。\n",
      "  - **心脏**：心脏大小正常，轮廓清晰，无明显增大或缩小。\n",
      "  - **膈肌**：膈肌位置正常，无异常抬高或凹陷。\n",
      "  - **骨骼**：肋骨、锁骨、肩胛骨等骨骼无明显骨折或畸形。\n",
      "\n",
      "- **其他信息**：\n",
      "  - 图片右上角有“L D R C”标记，表明该患者为左侧（L）和右侧（R）的胸部X光片。这通常用于标注患者体位。\n",
      "\n",
      "---\n",
      "\n",
      "### 结论\n",
      "\n",
      "综合以上分析，这张胸部X光片显示了正常胸腔解剖结构。肺部、心脏和骨骼均未见明显异常。因此，该患者目前的胸腔状况是正常的。\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:12:47.870511Z",
     "start_time": "2025-12-10T13:12:22.600941Z"
    }
   },
   "cell_type": "code",
   "source": "print(image_text_qa(\"../test_data/health-case.png\", \"提取图片中的所有文字\"))",
   "id": "f7a3f004d1f20fd4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "首都儿科研究所附属儿童医院\n",
      "门诊病历\n",
      "姓名： 性别：男；年龄： 患者科别：内科门诊；时间：2020-05-01 08:37\n",
      "主诉：间断气急，运动后出现较多，夜间频繁翻身，无打鼾，有口呼吸，呼吸道感染，1年3-4次，现病史：有AR病史，目前抗过敏治疗，症状有所改善\n",
      "既往史：体健。\n",
      "药物过敏史：否认。\n",
      "个人及家族史：有无精神病史；患儿母亲有荨麻疹病史；有哮喘家族史；否认传染病毒史及家族遗传病史\n",
      "体格检查：精神可，呼吸平稳，双肺呼吸音清，双肺未闻及啰音。心肺神经系统体查未见异常。\n",
      "辅助检查：过敏原检测：IgE升高。必要时行心脏、肺部检查\n",
      "初步诊断：胸闷\n",
      "过敏性鼻炎[变应性鼻炎]求诊\n",
      "处\n",
      "方\n",
      "名称 规格\n",
      "孟鲁司特钠咀嚼片 4mg x5片/盒 4mg 口服 每日1次\n",
      "采乐洛罗贴剂 0.5mg/贴 7贴/盒 1贴 外用 每晚1次\n",
      "用药天数嘱托 14天\n",
      "诊断：治疗：不适应诊。\n",
      "预\n",
      "约： 科室\n",
      "号\n",
      "专业\n",
      "辅助检查：\n",
      "打印时间：2020-05-01\n",
      "处理意见：\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:13:28.582074Z",
     "start_time": "2025-12-10T13:13:28.576637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. 进阶用法：多轮图文对话（支持多张图片和历史记录）\n",
    "def multi_turn_image_text_dialogue(history: list, new_image_path: str = None, new_prompt: str = \"\", max_new_tokens: int = 512) -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    多轮图文对话：输入历史记录（list of messages），可选新图片和新提示。\n",
    "    返回：新响应, 更新后的历史。\n",
    "    \n",
    "    history 示例（初始为空 list []）：\n",
    "    history = [\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": image1}, {\"type\": \"text\", \"text\": \"描述图片。\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": \"响应1\"}]},\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    使用：逐步调用，传入更新后的 history。\n",
    "    \"\"\"\n",
    "    if new_prompt or new_image_path:\n",
    "        new_content = []\n",
    "        if new_image_path:\n",
    "            image = Image.open(new_image_path)\n",
    "            new_content.append({\"type\": \"image\", \"image\": image})\n",
    "        if new_prompt:\n",
    "            new_content.append({\"type\": \"text\", \"text\": new_prompt})\n",
    "        \n",
    "        history.append({\"role\": \"user\", \"content\": new_content})\n",
    "    \n",
    "    # 应用聊天模板（多轮历史）\n",
    "    text = processor.apply_chat_template(history, tokenize=False, add_generation_prompt=True)\n",
    "    \n",
    "    # 收集所有图像（从历史中提取）\n",
    "    images = [item[\"image\"] for msg in history for item in msg[\"content\"] if item[\"type\"] == \"image\"]\n",
    "    \n",
    "    # 处理输入\n",
    "    inputs = processor(text=text, images=images if images else None, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 生成\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=max_new_tokens)\n",
    "    \n",
    "    # 解码\n",
    "    response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    \n",
    "    # 提取新 assistant 响应（去除历史）\n",
    "    response = response.split(\"assistant\\n\")[-1].strip() if \"assistant\\n\" in response else response\n",
    "    \n",
    "    # 更新历史：添加 assistant 响应\n",
    "    history.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": response}]})\n",
    "    \n",
    "    return response, history"
   ],
   "id": "3138c6f4a337f41e",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-10T13:15:02.189840Z",
     "start_time": "2025-12-10T13:14:41.341400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 第一轮：纯文本\n",
    "history = []\n",
    "print(\"\\n多轮对话示例：\")\n",
    "resp1, history = multi_turn_image_text_dialogue(history, new_prompt=\"你好。\")\n",
    "print(\"Round 1:\", resp1)\n",
    "    \n",
    "# 第二轮：加图片（假设 'example.jpg'）\n",
    "resp2, history = multi_turn_image_text_dialogue(history, new_image_path=\"../test_data/health-case.png\", new_prompt=\"这张图片是什么？\")\n",
    "print(\"Round 2:\", resp2)"
   ],
   "id": "4a3678197402194d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "多轮对话示例：\n",
      "Round 1: 你好！有什么我可以帮你的吗？\n",
      "Round 2: 根据图片内容分析，这是一份**儿童医院的门诊病历**。\n",
      "\n",
      "具体信息如下：\n",
      "- **医院**：首都儿科研究所附属儿童医院\n",
      "- **就诊时间**：2020年05月01日 08:37\n",
      "- **就诊科室**：呼吸内科门诊\n",
      "- **患者情况**：男童，因“间歇性气促，运动后出现较多，夜间频繁翻身，无打鼾，有口呼吸，呼吸道感染”就诊\n",
      "- **初步诊断**：胸闷、过敏性鼻炎（变应性鼻炎）\n",
      "- **处方**：孟鲁司特钠咀嚼片、利巴韦林贴剂\n",
      "- **复诊预约**：科室、号别（信息被遮挡）\n",
      "- **打印时间**：2020年05月01日\n",
      "\n",
      "这份病历记录了儿童患者因呼吸道感染、过敏性鼻炎等症状就诊的详细信息，包括症状、检查结果、诊断和处方等。\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f42f1afc00e7b465"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
